{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization after Lightning Pose training\n",
    "\n",
    "# We train Lightning Pose models on Rockfish cluster to use multiple GPUs (4GPUs/node = 40 GB*4 = 160 GB).\n",
    "# To visualize trainging results locally, \n",
    "# (1) Download the training outputs from Rockfish server (rockfish/.../lightning-pose-gpu/outputs) \n",
    "# to the local Lightning Pose folder (home/yiting/.../lightning-pose/outputs) \n",
    "# (2) Change data_dir, video_dir, test_videos_directory in config.yaml\n",
    "\n",
    "# Reference: litpose_training_demo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import os\n",
    "import lightning.pytorch as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# litpose_dir = r\"/home/yiting/Documents/GitHub/lightning-pose\"\n",
    "# config_path = r\"/home/yiting/Documents/LP_projects/LP_240726\"\n",
    "# config_name= \"config_hand-6cam.yaml\"\n",
    "output_dir = r\"/home/yiting/Documents/GitHub/lightning-pose/outputs\"\n",
    "model_dir = r\"2026-01-01/00-01-03\"\n",
    "# Load hydra configuration file\n",
    "cfg = OmegaConf.load(os.path.join(output_dir, model_dir, \"config.yaml\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions/diagnostics for labeled data (FiftyOne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating FiftyOne.Dataset for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override the default configs here:\n",
    "cfg.eval.hydra_paths=[os.path.join(output_dir, model_dir)] # you can add multiple output_directory2, output_directory3 to compare \n",
    "cfg.eval.fiftyone.dataset_name=\"260102\"\n",
    "cfg.eval.fiftyone.model_display_names=[\"260102\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting:  ['Dot_b1', 'Dot_b2', 'Dot_b3', 'Dot_l1', 'Dot_l2', 'Dot_l3', 'Dot_r1', 'Dot_r2', 'Dot_r3', 'Dot_t1', 'Dot_t2', 'Dot_t3', 'Index_DIP', 'Index_MCP', 'Index_PIP', 'Index_Tip', 'Middle_DIP', 'Middle_MCP', 'Middle_PIP', 'Middle_Tip', 'Palm', 'Ring_DIP', 'Ring_MCP', 'Ring_PIP', 'Ring_Tip', 'Small_DIP', 'Small_MCP', 'Small_PIP', 'Small_Tip', 'Thumb_CMC', 'Thumb_IP', 'Thumb_MCP', 'Thumb_Tip', 'Wrist_R', 'Wrist_U']\n",
      "Collecting ground-truth keypoints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1897/1897 [00:05<00:00, 366.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting predicted keypoints for model: 260102...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1897/1897 [00:04<00:00, 383.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "Appending fo.Keypoints to fo.Sample objects for each image...\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1897/1897 [00:00<00:00, 46785.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Adding samples to the dataset...\n",
      "--------------------------------\n",
      " 100% |███████████████| 1897/1897 [19.9s elapsed, 0s remaining, 104.9 samples/s]      \n",
      "-----\n",
      "Done!\n",
      "-----\n",
      "---------------------------------------------------\n",
      "Checking FiftyOne.Dataset by computing metadata... \n",
      "---------------------------------------------------\n",
      "Computing metadata...\n",
      " 100% |███████████████| 1897/1897 [5.3s elapsed, 0s remaining, 392.6 samples/s]      \n",
      "------------------------------------------------------------------------------------------\n",
      "Created FiftyOne dataset called: 260102. To access it in python: fo.load_dataset(\"260102\")\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "from lightning_pose.utils.fiftyone import check_dataset, FiftyOneImagePlotter\n",
    "\n",
    "# initializes everything\n",
    "fo_plotting_instance = FiftyOneImagePlotter(cfg=cfg)\n",
    "\n",
    "# internally loops over models\n",
    "dataset = fo_plotting_instance.create_dataset()\n",
    "\n",
    "# create metadata and print if there are problems\n",
    "check_dataset(dataset)\n",
    "fo_plotting_instance.dataset_info_print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=0926028c-1ca5-4a2c-b3a5-88e50e6b3921\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb2a1209330>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset:     -\n",
       "Session URL: http://localhost:5151/"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch the FiftyOne UI\n",
    "fo.launch_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch previously created FiftyOne.Dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "dataset = fo.load_dataset(\"251031\")\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List dataset names \n",
    "fo.list_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot video predictions and unsupervised losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from lightning_pose.apps.utils import build_precomputed_metrics_df, get_col_names, concat_dfs\n",
    "from lightning_pose.apps.utils import update_vid_metric_files_list\n",
    "from lightning_pose.apps.utils import get_model_folders, get_model_folders_vis\n",
    "from lightning_pose.apps.plots import plot_precomputed_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which model(s) to use\n",
    "model_folders = get_model_folders(output_dir)\n",
    "\n",
    "# get the last two levels of each path to be presented to user\n",
    "model_names = get_model_folders_vis(model_folders)\n",
    "\n",
    "# get prediction files for each model\n",
    "prediction_files = update_vid_metric_files_list(video=\"2025-08-19_08-45-48_camTo\", model_preds_folders=model_folders)\n",
    "\n",
    "# load data\n",
    "dframes_metrics = defaultdict(dict)\n",
    "dframes_traces = {}\n",
    "for p, model_pred_files in enumerate(prediction_files):\n",
    "    model_name = model_names[p]\n",
    "    model_folder = model_folders[p]\n",
    "    for model_pred_file in model_pred_files:\n",
    "        model_pred_file_path = os.path.join(model_folder, \"video_preds\", model_pred_file)\n",
    "        if not isinstance(model_pred_file, Path):\n",
    "            model_pred_file.seek(0)  # reset buffer after reading\n",
    "        if \"pca\" in str(model_pred_file) or \"temporal\" in str(model_pred_file) or \"pixel\" in str(model_pred_file):\n",
    "            dframe = pd.read_csv(model_pred_file_path, index_col=None)\n",
    "            dframes_metrics[model_name][str(model_pred_file)] = dframe\n",
    "        else:\n",
    "            dframe = pd.read_csv(model_pred_file_path, header=[1, 2], index_col=0)\n",
    "            dframes_traces[model_name] = dframe\n",
    "            dframes_metrics[model_name][\"confidence\"] = dframe\n",
    "        data_types = dframe.iloc[:, -1].unique()\n",
    "\n",
    "# compute metrics\n",
    "# concat dataframes, collapsing hierarchy and making df fatter.\n",
    "df_concat, keypoint_names = concat_dfs(dframes_traces)\n",
    "df_metrics = build_precomputed_metrics_df(\n",
    "    dframes=dframes_metrics, keypoint_names=keypoint_names)\n",
    "metric_options = list(df_metrics.keys())\n",
    "\n",
    "# print keypoint names; select one of these to plot below\n",
    "print(keypoint_names)\n",
    "\n",
    "# NOTE: you can ignore all errors and warnings of the type:\n",
    "#    No runtime found, using MemoryCacheStorageManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot video traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun this cell each time you want to update the keypoint\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def on_change(change):\n",
    "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
    "        clear_output()\n",
    "        cols = get_col_names(change[\"new\"], \"x\", dframes_metrics.keys())\n",
    "        fig_traces = plot_precomputed_traces(df_metrics, df_concat, cols)\n",
    "        fig_traces.show()\n",
    "\n",
    "# create a Dropdown widget\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=keypoint_names,\n",
    "    value=None,  # Set the default selected value\n",
    "    description=\"Select keypoint:\",\n",
    ")\n",
    "\n",
    "# update plot upon change\n",
    "dropdown.observe(on_change)\n",
    "\n",
    "# display widget\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See instruction https://lightning-pose.readthedocs.io/en/latest/source/user_guide/inference.html \n",
    "# eval.hydra_paths: path to models to use for prediction\n",
    "# eval.test_videos_directory: path to a directory containing videos to run inference on\n",
    "# eval.save_vids_after_training: if true, the script will also save a copy of the full video with model predictions overlaid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on Rockfish Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Edit config file and run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminal:\n",
    "# python scripts/predict_new_vids.py --config-path=<PATH/TO/YOUR/CONFIGS/DIR> --config-name=<CONFIG_NAME.yaml>\n",
    "#\n",
    "# python scripts/predict_new_vids.py --config-path=/home/yiting/Documents/LP_projects/LP_241128 --config-name=config_hand-1cam-4gpu.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Override these arguments in the command line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminal:\n",
    "# python scripts/predict_new_vids.py --config-path=<PATH/TO/YOUR/CONFIGS/DIR> --config-name=<CONFIG_NAME.yaml> eval.hydra_paths=[\"YYYY-MM-DD/HH-MM-SS/\"] eval.test_videos_directory=/absolute/path/to/videos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "litpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
