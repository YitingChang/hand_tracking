{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c067ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fbb3ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_frame(vid_path, frame_idx=10):\n",
    "    '''\n",
    "    Extract a single frame from a video\n",
    "    Args:\n",
    "        vid_path: video path\n",
    "        frame_idx: the frame index \n",
    "    '''\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd80525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rois(json_path=\"camera_rois.json\"):\n",
    "    if not os.path.exists(json_path):\n",
    "        print(\"Error: ROI file not found.\")\n",
    "        return {}\n",
    "        \n",
    "    with open(json_path, 'r') as f:\n",
    "        roi_data = json.load(f)\n",
    "    \n",
    "    return roi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f84f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_camera_shift(test_img, template, x_base, y_base):\n",
    "    ''' \n",
    "    Template Matching:\n",
    "    We search for the 'template' inside 'test_img'.\n",
    "    TM_CCOEFF_NORMED is best for lighting invariance.\n",
    "\n",
    "    Args:\n",
    "    test_img: test image\n",
    "    template: ROI of base image\n",
    "    x_base: x location of template \n",
    "    y_base: y location of template \n",
    "    '''\n",
    "    # Template Matching\n",
    "    # We search for the 'template' inside 'test_img'\n",
    "    # TM_CCOEFF_NORMED is best for lighting invariance.\n",
    "    res = cv2.matchTemplate(test_img, template, cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "    # Get the location of the best match\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    \n",
    "    # For TM_CCOEFF_NORMED, the best match is the maximum value (max_loc)\n",
    "    # max_loc is (x, y) top-left corner\n",
    "    x_curr, y_curr = max_loc\n",
    "\n",
    "    # 6. Calculate Shift\n",
    "    shift_x = x_curr - x_base\n",
    "    shift_y = y_curr - y_base\n",
    "    \n",
    "    # Confidence score (0 to 1). If < 0.8, the match might be wrong (e.g. object blocked).\n",
    "    confidence = max_val \n",
    "\n",
    "    status_x_str = f\"{shift_x:+d} px\".ljust(8)\n",
    "    status_y_str = f\"{shift_y:+d} px\".ljust(8)\n",
    "\n",
    "    return status_x_str, status_y_str, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383ea1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camTo | +0 px    | +0 px    | 1.00\n",
      "camBL | +0 px    | +0 px    | 1.00\n",
      "camTR | +0 px    | +0 px    | 1.00\n",
      "camTL | +0 px    | +0 px    | 1.00\n",
      "camBR | +0 px    | +0 px    | 1.00\n"
     ]
    }
   ],
   "source": [
    "# Setting\n",
    "cameras = {'camTo', 'camTL', 'camTR', 'camBL', 'camBR'}\n",
    "frame_idx = 10\n",
    "rois_path = '/media/yiting/NewVolume/Data/Videos/Camera_Alignment/ROIs/2025-12-18_camera_rois.json'\n",
    "video_folder_dir_base = '/media/yiting/NewVolume/Data/Videos/Camera_Alignment/2025-12-18/cameras/2025-12-18_11-22-05_062292'\n",
    "video_folder_dir_curr = '/media/yiting/NewVolume/Data/Videos/Camera_Alignment/2025-12-18/cameras/2025-12-18_11-22-05_062292'\n",
    "\n",
    "# Load ROIs\n",
    "camera_rois = load_rois(rois_path)\n",
    "\n",
    "for camera in cameras:\n",
    "    # Load baseline frame\n",
    "    video_path_base = os.path.join(video_folder_dir_base, f'{camera}-orig.mp4')\n",
    "    frame_base = get_single_frame(video_path_base, frame_idx=frame_idx)\n",
    "    gray_base = cv2.cvtColor(frame_base, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Create the template image\n",
    "    x_base, y_base, w, h = camera_rois[camera]\n",
    "    template = gray_base[y_base:y_base+h, x_base:x_base+w]\n",
    "\n",
    "    # Load current frame\n",
    "    video_path_curr = os.path.join(video_folder_dir_curr, f'{camera}-orig.mp4')\n",
    "    frame_curr = get_single_frame(video_path_curr, frame_idx=frame_idx)\n",
    "    gray_curr = cv2.cvtColor(frame_curr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Template matching\n",
    "    status_x_str, status_y_str, confidence = quantify_camera_shift(gray_curr, template, x_base, y_base)\n",
    "    print(f\"{camera} | {status_x_str} | {status_y_str} | {confidence:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hand-trk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
