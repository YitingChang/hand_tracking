{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use DeepLabCut to train a single network to track key points of monkey hand from multiple camera views.\n",
    "\\\n",
    "This notebook is based on a template (Demo_yourowndata.ipynb)from DeepLabCut Github (https://github.com/DeepLabCut/DeepLabCut).\n",
    "\n",
    "It illustrates how to: \n",
    "- prepare videos for DLC (cropping, down sampling if needed)\n",
    "- create a project\n",
    "- extract training frames\n",
    "- label the frames\n",
    "- plot the labeled images\n",
    "- create a training set\n",
    "- train a network\n",
    "- evaluate a network\n",
    "- analyze a novel video\n",
    "- create an automatically labeled video\n",
    "- plot the trajectories\n",
    "\n",
    "Note:\\\n",
    "Open the gui in the terminal if this notebook fails to open the gui.\n",
    "\n",
    "Reference: \\\n",
    "Paper: https://www.nature.com/articles/s41596-019-0176-0 \n",
    "\\\n",
    "Pre-print: https://www.biorxiv.org/content/biorxiv/early/2018/11/24/476531.full.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "- make videos from images\n",
    "- crop and down sample videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Make videos from images if needed.\n",
    "# DeepLabCut requires videos not images.\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "video_main_dir = r'E:\\Monkey_project_videos'\n",
    "# session_name = ['2023-08-03_15-33-29', '2023-08-03_15-38-37']\n",
    "session_name = ['Calibration_230804']\n",
    "camera_name_dic = {\"19472072\": \"cam-A\", \"19472089\": \"cam-B\"}\n",
    "video_save_path = r'E:\\Monkey_project_videos\\Calibration_230804'\n",
    "for s in session_name:\n",
    "    for i, (k, v) in enumerate(camera_name_dic.items()):\n",
    "        image_folder = os.path.join(video_main_dir,s,v)\n",
    "        # video_name = os.path.join(video_save_path, 'cam' + k + '_video' + s + '.avi')\n",
    "        video_name = os.path.join(video_save_path, 'cam' + k + '_video' + s + '.mp4')\n",
    "\n",
    "        images = [img for img in os.listdir(image_folder) if img.endswith(\".tiff\")]\n",
    "        frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "        height, width, layers = frame.shape\n",
    "\n",
    "        video = cv2.VideoWriter(video_name,  #Provide a file to write the video to\n",
    "            # fourcc=cv2.VideoWriter_fourcc('X','V','I','D'), # code for avi\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v'), # code for mp4\n",
    "            fps=20,                                        #How many frames do you want to display per second in your video?\n",
    "            frameSize=(width, height))                     #The size of the frames you are writing\n",
    "\n",
    "        for image in images:\n",
    "            video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop and down sample videos\n",
    "# image_width = 1920 # pixels\n",
    "# image_height = 1200 # pixels\n",
    "# video_save_path = r'E:\\Monkey_project_videos\\2023-08-03-videos'\n",
    "# videos = [vid for vid in os.listdir(video_save_path) if vid.endswith(\".avi\")]\n",
    "# down_sample_ratio = 0.8\n",
    "# for v in videos:\n",
    "#     video_name = os.path.join(video_save_path, v)\n",
    "#     downsampled_video_name = deeplabcut.DownSampleVideo(video_name,\n",
    "#                                width=image_width*down_sample_ratio,\n",
    "#                                height=image_height*down_sample_ratio,\n",
    "#                                outsuffix='_downsampled')\n",
    "#     cropped_downsampled_video_name = deeplabcut.CropVideo(downsampled_video_name,\n",
    "#                                                      origin_x=250, origin_y=100,\n",
    "#                                                      width=800, height=800,\n",
    "#                                                      outsuffix='_cropped')\n",
    "# deeplabcut.DownSampleVideo?\n",
    "# deeplabcut.CropVideo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Crop \n",
    "# image_width = 1920 # pixels\n",
    "# image_height = 1200 # pixels\n",
    "# video_save_path = r'E:\\Monkey_project_videos\\2023-08-03-videos'\n",
    "# videos = [vid for vid in os.listdir(video_save_path) if vid.endswith(\".avi\")]\n",
    "# for v in videos:\n",
    "#     video_name = os.path.join(video_save_path, v)\n",
    "#     cropped_video_name = deeplabcut.CropVideo(video_name,\n",
    "#                                              origin_x=500, origin_y=150,\n",
    "#                                              width=850, height=850,\n",
    "#                                              outsuffix='_cropped')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Create a new project\n",
    "\n",
    "It is always good idea to keep the projects separate if you want to use different networks to analze your data. You should use one project if you are tracking similar subjects/items even if in different environments. This function creates a new project with sub-directories and a basic configuration file in the user defined directory otherwise the project is created in the current working directory.\n",
    "\n",
    "You can always add new videos (for lableing more data) to the project at any stage of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.5...\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7"
   },
   "outputs": [],
   "source": [
    "task='Testing2Cam' # Enter the name of your experiment Task\n",
    "experimenter='Yiting' # Enter the name of the experimenter\n",
    "video=['E:/Monkey_project_videos/2023-08-03_videos'] # Enter the paths of your videos OR FOLDER you want to grab frames from.\n",
    "\n",
    "# path_config_file=deeplabcut.create_new_project(task,experimenter,video,copy_videos=True,working_directory=\"C:/Users/Yiting/Desktop\",) \n",
    "\n",
    "# NOTE: The function returns the path, where your project is. \n",
    "# You could also enter this manually (e.g. if the project is already created and you want to pick up, where you stopped...)\n",
    "path_config_file = r'C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\config.yaml' # Enter the path of the config file that was just created from the above step (check the folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, go edit the config.yaml file that was created! \n",
    "Add your body part labels, edit the number of frames to extract per video, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that you can see more information about ANY function by adding a ? at the end,  i.e. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_frames?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0yXW0bx1oEJA"
   },
   "source": [
    "## Extract frames from videos \n",
    "A key point for a successful feature detector is to select diverse frames, which are typical for the behavior you study that should be labeled.\n",
    "\n",
    "This function selects N frames either uniformly sampled from a particular video (or folder) ('uniform'). Note: this might not yield diverse frames, if the behavior is sparsely distributed (consider using kmeans), and/or select frames manually etc.\n",
    "\n",
    "Also make sure to get select data from different (behavioral) sessions and different animals if those vary substantially (to train an invariant feature detector).\n",
    "\n",
    "Individual images should not be too big (i.e. < 850 x 850 pixel). Although this can be taken care of later as well, it is advisable to crop the frames, to remove unnecessary parts of the frame as much as possible.\n",
    "\n",
    "Always check the output of cropping. If you are happy with the results proceed to labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1ulumCuoEJC"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#there are other ways to grab frames, such as uniformly; please see the paper:\n",
    "\n",
    "#AUTOMATIC:\n",
    "deeplabcut.extract_frames(path_config_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AND/OR:\n",
    "#SELECT RARE EVENTS MANUALLY:\n",
    "%gui wx\n",
    "deeplabcut.extract_frames(path_config_file,'manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg',warn=False, force=True)\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.get_backend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gjn6ZDonoEJH"
   },
   "source": [
    "## Label the extracted frames\n",
    "\n",
    "Only videos in the config file can be used to extract the frames. Extracted labels for each video are stored in the project directory under the subdirectory **'labeled-data'**. Each subdirectory is named after the name of the video. The toolbox has a labeling toolbox which could be used for labeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyROSOiEoEJI"
   },
   "outputs": [],
   "source": [
    "%gui wx\n",
    "deeplabcut.label_frames(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vim95ZvkPSeN"
   },
   "source": [
    "## Check the labels\n",
    "\n",
    "[OPTIONAL] Checking if the labels were created and stored correctly is beneficial for training, since labeling is one of the most critical parts for creating the training dataset. The DeepLabCut toolbox provides a function `check\\_labels'  to do so. It is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwvgPJouPP2O"
   },
   "outputs": [],
   "source": [
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "of87fOjgPqzH"
   },
   "source": [
    "If the labels need adjusted, you can use relauch the labeling GUI to move them around, save, and re-plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "\n",
    "This function generates the training data information for network training based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles if they want to benchmark the performance (typcailly, 1 is what you will set, so you pass nothing!). \n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**. For most all use cases we have seen, the defaults are perfectly fine.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)\n",
    "#remember, there are several networks you can pick, the default is resnet-50!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training:\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW"
   },
   "outputs": [],
   "source": [
    "deeplabcut.train_network(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.train_network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This function evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg"
   },
   "outputs": [],
   "source": [
    "deeplabcut.evaluate_network(path_config_file, plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos\n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [],
   "source": [
    "videofile_path = [r'C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos'] #Enter a folder OR a list of videos to analyze.\n",
    "# videofile_path = ['videos/video3.avi','videos/video4.avi'] #Enter a folder OR a list of videos to analyze.\n",
    "\n",
    "deeplabcut.analyze_videos(path_config_file,videofile_path, videotype='.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [optional step]\n",
    "\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. This step has many options, so please look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(path_config_file,[r'C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472072_video2023-08-03_15-43-34.avi'],\n",
    "                                 p_bound = 0.7) #pass a specific video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [],
   "source": [
    "%gui wx\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Afterwards, if you want to look at the adjusted frames, you can load them in the main GUI by running: ``deeplabcut.label_frames(path_config_file)``\n",
    "\n",
    "(you can add a new \"cell\" below to add this code!)\n",
    "\n",
    "#### Once all folders are relabeled, check the labels again! If you are not happy, adjust them in the main GUI:\n",
    "\n",
    "``deeplabcut.label_frames(path_config_file)``\n",
    "\n",
    "Check Labels:\n",
    "\n",
    "``deeplabcut.check_labels(path_config_file)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [],
   "source": [
    "#NOW, merge this with your original data:\n",
    "\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refinement of labels and appending them to the original dataset, this creates a new iteration of training dataset. This is automatically set in the config.yaml file, so let's get training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7"
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This function is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. \n",
    "\n",
    "THIS HAS MANY FUN OPTIONS! \n",
    "\n",
    "``deeplabcut.create_labeled_video(config, videos, videotype='avi', shuffle=1, trainingsetindex=0, filtered=False, save_frames=False, Frames2plot=None, delete=False, displayedbodyparts='all', codec='mp4v', outputframerate=None, destfolder=None, draw_skeleton=False, trailpoints=0, displaycropped=False)``\n",
    "\n",
    "So please check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_labeled_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvideos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvideotype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrainingsetindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfiltered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfastmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msave_frames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeypoints_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mFrames2plot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdisplayedbodyparts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdisplayedindividuals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcodec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mp4v'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0moutputframerate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdestfolder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdraw_skeleton\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrailpoints\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdisplaycropped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcolor_by\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bodypart'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmodelprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0minit_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrack_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msuperanimal_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpcutoff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskeleton\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskeleton_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'white'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdotsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcolormap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rainbow'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0malphavalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Labels the bodyparts in a video.\n",
       "\n",
       "Make sure the video is already analyzed by the function\n",
       "``deeplabcut.analyze_videos``.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "config : string\n",
       "    Full path of the config.yaml file.\n",
       "\n",
       "videos : list[str]\n",
       "    A list of strings containing the full paths to videos for analysis or a path\n",
       "    to the directory, where all the videos with same extension are stored.\n",
       "\n",
       "videotype: str, optional, default=\"\"\n",
       "    Checks for the extension of the video in case the input to the video is a\n",
       "    directory. Only videos with this extension are analyzed.\n",
       "    If left unspecified, videos with common extensions\n",
       "    ('avi', 'mp4', 'mov', 'mpeg', 'mkv') are kept.\n",
       "\n",
       "shuffle : int, optional, default=1\n",
       "    Number of shuffles of training dataset.\n",
       "\n",
       "trainingsetindex: int, optional, default=0\n",
       "    Integer specifying which TrainingsetFraction to use.\n",
       "    Note that TrainingFraction is a list in config.yaml.\n",
       "\n",
       "filtered: bool, optional, default=False\n",
       "    Boolean variable indicating if filtered output should be plotted rather than\n",
       "    frame-by-frame predictions. Filtered version can be calculated with\n",
       "    ``deeplabcut.filterpredictions``.\n",
       "\n",
       "fastmode: bool, optional, default=True\n",
       "    If ``True``, uses openCV (much faster but less customization of video) instead\n",
       "    of matplotlib if ``False``. You can also \"save_frames\" individually or not in\n",
       "    the matplotlib mode (if you set the \"save_frames\" variable accordingly).\n",
       "    However, using matplotlib to create the frames it therefore allows much more\n",
       "    flexible (one can set transparency of markers, crop, and easily customize).\n",
       "\n",
       "save_frames: bool, optional, default=False\n",
       "    If ``True``, creates each frame individual and then combines into a video.\n",
       "    Setting this to ``True`` is relatively slow as it stores all individual frames.\n",
       "\n",
       "keypoints_only: bool, optional, default=False\n",
       "    By default, both video frames and keypoints are visible. If ``True``, only the\n",
       "    keypoints are shown. These clips are an hommage to Johansson movies,\n",
       "    see https://www.youtube.com/watch?v=1F5ICP9SYLU and of course his seminal\n",
       "    paper: \"Visual perception of biological motion and a model for its analysis\"\n",
       "    by Gunnar Johansson in Perception & Psychophysics 1973.\n",
       "\n",
       "Frames2plot: List[int] or None, optional, default=None\n",
       "    If not ``None`` and ``save_frames=True`` then the frames corresponding to the\n",
       "    index will be plotted. For example, ``Frames2plot=[0,11]`` will plot the first\n",
       "    and the 12th frame.\n",
       "\n",
       "displayedbodyparts: list[str] or str, optional, default=\"all\"\n",
       "    This selects the body parts that are plotted in the video. If ``all``, then all\n",
       "    body parts from config.yaml are used. If a list of strings that are a subset of\n",
       "    the full list. E.g. ['hand','Joystick'] for the demo\n",
       "    Reaching-Mackenzie-2018-08-30/config.yaml to select only these body parts.\n",
       "\n",
       "displayedindividuals: list[str] or str, optional, default=\"all\"\n",
       "    Individuals plotted in the video.\n",
       "    By default, all individuals present in the config will be showed.\n",
       "\n",
       "codec: str, optional, default=\"mp4v\"\n",
       "    Codec for labeled video. For available options, see\n",
       "    http://www.fourcc.org/codecs.php. Note that this depends on your ffmpeg\n",
       "    installation.\n",
       "\n",
       "outputframerate: int or None, optional, default=None\n",
       "    Positive number, output frame rate for labeled video (only available for the\n",
       "    mode with saving frames.) If ``None``, which results in the original video\n",
       "    rate.\n",
       "\n",
       "destfolder: string or None, optional, default=None\n",
       "    Specifies the destination folder that was used for storing analysis data. If\n",
       "    ``None``, the path of the video file is used.\n",
       "\n",
       "draw_skeleton: bool, optional, default=False\n",
       "    If ``True`` adds a line connecting the body parts making a skeleton on each\n",
       "    frame. The body parts to be connected and the color of these connecting lines\n",
       "    are specified in the config file.\n",
       "\n",
       "trailpoints: int, optional, default=0\n",
       "    Number of previous frames whose body parts are plotted in a frame\n",
       "    (for displaying history).\n",
       "\n",
       "displaycropped: bool, optional, default=False\n",
       "    Specifies whether only cropped frame is displayed (with labels analyzed\n",
       "    therein), or the original frame with the labels analyzed in the cropped subset.\n",
       "\n",
       "color_by : string, optional, default='bodypart'\n",
       "    Coloring rule. By default, each bodypart is colored differently.\n",
       "    If set to 'individual', points belonging to a single individual are colored the\n",
       "    same.\n",
       "\n",
       "modelprefix: str, optional, default=\"\"\n",
       "    Directory containing the deeplabcut models to use when evaluating the network.\n",
       "    By default, the models are assumed to exist in the project folder.\n",
       "\n",
       "init_weights: str,\n",
       "    Checkpoint path to the super model\n",
       "track_method: string, optional, default=\"\"\n",
       "    Specifies the tracker used to generate the data.\n",
       "    Empty by default (corresponding to a single animal project).\n",
       "    For multiple animals, must be either 'box', 'skeleton', or 'ellipse' and will\n",
       "    be taken from the config.yaml file if none is given.\n",
       "\n",
       "overwrite: bool, optional, default=False\n",
       "    If ``True`` overwrites existing labeled videos.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "    results : list[bool]\n",
       "    ``True`` if the video is successfully created for each item in ``videos``.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "\n",
       "Create the labeled video for a single video\n",
       "\n",
       ">>> deeplabcut.create_labeled_video(\n",
       "        '/analysis/project/reaching-task/config.yaml',\n",
       "        ['/analysis/project/videos/reachingvideo1.avi'],\n",
       "    )\n",
       "\n",
       "Create the labeled video for a single video and store the individual frames\n",
       "\n",
       ">>> deeplabcut.create_labeled_video(\n",
       "        '/analysis/project/reaching-task/config.yaml',\n",
       "        ['/analysis/project/videos/reachingvideo1.avi'],\n",
       "        fastmode=True,\n",
       "        save_frames=True,\n",
       "    )\n",
       "\n",
       "Create the labeled video for multiple videos\n",
       "\n",
       ">>> deeplabcut.create_labeled_video(\n",
       "        '/analysis/project/reaching-task/config.yaml',\n",
       "        [\n",
       "            '/analysis/project/videos/reachingvideo1.avi',\n",
       "            '/analysis/project/videos/reachingvideo2.avi',\n",
       "        ],\n",
       "    )\n",
       "\n",
       "Create the labeled video for all the videos with an .avi extension in a directory.\n",
       "\n",
       ">>> deeplabcut.create_labeled_video(\n",
       "        '/analysis/project/reaching-task/config.yaml',\n",
       "        ['/analysis/project/videos/'],\n",
       "    )\n",
       "\n",
       "Create the labeled video for all the videos with an .mp4 extension in a directory.\n",
       "\n",
       ">>> deeplabcut.create_labeled_video(\n",
       "        '/analysis/project/reaching-task/config.yaml',\n",
       "        ['/analysis/project/videos/'],\n",
       "        videotype='mp4',\n",
       "    )\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\yiting\\anaconda3\\envs\\deeplabcut\\lib\\site-packages\\deeplabcut\\utils\\make_labeled_video.py\n",
       "\u001b[1;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "videofile_path = [r'C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos'] #Enter a folder OR a list of videos to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Starting to process video: C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472089_video2023-08-03_15-38-21.avi\n",
      "Loading C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472089_video2023-08-03_15-38-21.avi and data.\n",
      "Duration of video [s]: 11.3, recorded with 100 fps!\n",
      "Overall # of frames: 1130 with cropped frame dimensions: 1920 1200\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1130/1130 [00:20<00:00, 53.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472072_video2023-08-03_15-33-29.avi\n",
      "Loading C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472072_video2023-08-03_15-33-29.avi and data.\n",
      "Duration of video [s]: 8.83, recorded with 100 fps!\n",
      "Overall # of frames: 883 with cropped frame dimensions: 1920 1200\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 883/883 [00:20<00:00, 43.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472072_video2023-08-03_15-43-34.avi\n",
      "Loading C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472072_video2023-08-03_15-43-34.avi and data.\n",
      "Duration of video [s]: 11.38, recorded with 100 fps!\n",
      "Overall # of frames: 1138 with cropped frame dimensions: 1920 1200\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [00:21<00:00, 54.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472072_video2023-08-03_15-38-37.avi\n",
      "Loading C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472072_video2023-08-03_15-38-37.avi and data.\n",
      "Duration of video [s]: 8.21, recorded with 100 fps!\n",
      "Overall # of frames: 821 with cropped frame dimensions: 1920 1200\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 821/821 [00:15<00:00, 51.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472089_video2023-08-03_15-43-34.avi\n",
      "Loading C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472089_video2023-08-03_15-43-34.avi and data.\n",
      "Duration of video [s]: 11.38, recorded with 100 fps!\n",
      "Overall # of frames: 1138 with cropped frame dimensions: 1920 1200\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [00:21<00:00, 53.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472072_video2023-08-03_15-33-04.avi\n",
      "Loading C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472072_video2023-08-03_15-33-04.avi and data.\n",
      "Duration of video [s]: 9.39, recorded with 100 fps!\n",
      "Overall # of frames: 939 with cropped frame dimensions: 1920 1200\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 939/939 [00:17<00:00, 53.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472089_video2023-08-03_15-33-04.avi\n",
      "Loading C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472089_video2023-08-03_15-33-04.avi and data.\n",
      "Duration of video [s]: 9.39, recorded with 100 fps!\n",
      "Overall # of frames: 939 with cropped frame dimensions: 1920 1200\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 939/939 [00:17<00:00, 53.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472072_video2023-08-03_15-38-21.avi\n",
      "Loading C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472072_video2023-08-03_15-38-21.avi and data.\n",
      "Duration of video [s]: 11.3, recorded with 100 fps!\n",
      "Overall # of frames: 1130 with cropped frame dimensions: 1920 1200\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1130/1130 [00:21<00:00, 51.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472089_video2023-08-03_15-38-37.avi\n",
      "Loading C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472089_video2023-08-03_15-38-37.avi and data.\n",
      "Duration of video [s]: 8.21, recorded with 100 fps!\n",
      "Overall # of frames: 821 with cropped frame dimensions: 1920 1200\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 821/821 [00:15<00:00, 53.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472089_video2023-08-03_15-33-29.avi\n",
      "Loading C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472089_video2023-08-03_15-33-29.avi and data.\n",
      "Duration of video [s]: 8.83, recorded with 100 fps!\n",
      "Overall # of frames: 883 with cropped frame dimensions: 1920 1200\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 883/883 [00:16<00:00, 53.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, True, True, True, True, True]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update pcutoff in config_file\n",
    "deeplabcut.create_labeled_video(path_config_file,videofile_path,filtered=False,draw_skeleton=True,pcutoff=0.2,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472072_video2023-08-03_15-33-29.avi\n",
      "Loading C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472072_video2023-08-03_15-33-29.avi and data.\n",
      "Duration of video [s]: 8.83, recorded with 100.0 fps!\n",
      "Overall # of frames: 883 with cropped frame dimensions: 1920 1200\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 883/883 [11:15<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled video C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472072_video2023-08-03_15-33-29DLC_resnet50_Testing2CamAug5shuffle1_100000_labeled.mp4 successfully created.\n",
      "Starting to process video: C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472089_video2023-08-03_15-33-29.avi\n",
      "Loading C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472089_video2023-08-03_15-33-29.avi and data.\n",
      "Duration of video [s]: 8.83, recorded with 100.0 fps!\n",
      "Overall # of frames: 883 with cropped frame dimensions: 1920 1200\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 883/883 [13:22<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled video C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472089_video2023-08-03_15-33-29DLC_resnet50_Testing2CamAug5shuffle1_100000_labeled.mp4 successfully created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save_frames = True -> very slow\n",
    "videofile_path = [r'C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472072_video2023-08-03_15-33-29.avi',\n",
    "                 r'C:\\Users\\Yiting\\Desktop\\Testing2Cam-Yiting-2023-08-05\\videos\\cam19472089_video2023-08-03_15-33-29.avi']\n",
    "deeplabcut.create_labeled_video(path_config_file,videofile_path,filtered=False,\n",
    "                                draw_skeleton=True,pcutoff=0.2,overwrite=True,\n",
    "                               save_frames=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook #for making interactive plots.\n",
    "deeplabcut.plot_trajectories(path_config_file,videofile_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:DEEPLABCUT]",
   "language": "python",
   "name": "conda-env-DEEPLABCUT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
