{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anipose_label_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "import toml\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "from aniposelib.cameras import CameraGroup\n",
    "from anipose.triangulate import load_offsets_dict\n",
    "from anipose.label_combined import visualize_combined\n",
    "\n",
    "from anipose.common import make_process_fun, get_nframes, \\\n",
    "    get_video_name, get_cam_name, \\\n",
    "    get_video_params, get_video_params_cap, \\\n",
    "    get_data_length, natural_keys, true_basename, find_calibration_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '/home/yiting/Documents/Anipose_projects/config_2cam.toml'\n",
    "session_path = '/home/yiting/Documents/Anipose_projects/Anipose_240624'\n",
    "p3d_file = os.path.join(session_path,'vid_231121-102936_.csv')\n",
    "p3d_video = os.path.join(session_path,'vid_231121-102936_.mp4')\n",
    "calibration_file = os.path.join(session_path,'calibration','calibration.toml')\n",
    "videos_raw_folder = os.path.join(session_path,'videos_raw')\n",
    "output_video = os.path.join(session_path,'label_combined.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TOML file\n",
    "config = toml.load(config_file)\n",
    "\n",
    "# Loading calibration file\n",
    "cgroup = CameraGroup.load(calibration_file)\n",
    "cam_names = ['A', 'B']\n",
    "\n",
    "# Load offsets_dict\n",
    "offsets_dict = load_offsets_dict(config, cam_names, videos_raw_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw 2d and 3d labeled videos\n",
    "video_ext = config['video_extension']\n",
    "vid_fnames_2d = glob(os.path.join(videos_raw_folder, \"*.\"+video_ext))\n",
    "\n",
    "vid_fnames_3d = glob(os.path.join(session_path,\"p3d.mp4\"))\n",
    "\n",
    "fnames_2d = defaultdict(list)\n",
    "for vid in vid_fnames_2d:\n",
    "    vidname = get_video_name(config, vid)\n",
    "    fnames_2d[vidname].append(vid)\n",
    "\n",
    "fnames_3d = defaultdict(list)\n",
    "for vid in vid_fnames_3d:\n",
    "    vidname = true_basename(vid)\n",
    "    fnames_3d[vidname].append(vid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vid_231121-102936_\n",
      "defaultdict(<class 'list'>, {'vid_231121-102936_': ['/home/yiting/Documents/Anipose_projects/Anipose_240624/videos_raw/vid_231121-102936_camB.mp4', '/home/yiting/Documents/Anipose_projects/Anipose_240624/videos_raw/vid_231121-102936_camA.mp4']})\n"
     ]
    }
   ],
   "source": [
    "print(vidname)\n",
    "print(fnames_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {})\n"
     ]
    }
   ],
   "source": [
    "print(fnames_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For current trial\n",
    "basename = true_basename(vid_fnames_3d[0])\n",
    "fname_3d_current = fnames_3d[basename][0]\n",
    "fnames_2d_current = fnames_2d[basename]\n",
    "fnames_2d_current = sorted(fnames_2d_current, key=natural_keys)\n",
    "\n",
    "cam_names = [get_cam_name(config, fname) for fname in fnames_2d_current]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_combined(config, p3d_file, cgroup, offsets_dict, fnames_2d_current, fname_3d_current, output_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_fname = p3d_file\n",
    "out_fname = output_video\n",
    "# visualize_combined(config, p3d_file, cgroup, offsets_dict, fnames_2d_current, fname_3d_current, output_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_3d = fnames_3d[basename][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_load_3d = (cgroup is not None) and \\\n",
    "    (pose_fname is not None) and \\\n",
    "    (offsets_dict is not None)\n",
    "\n",
    "if should_load_3d:\n",
    "    scheme, bodyparts, points_2d_proj = get_projected_points(config, pose_fname, cgroup, offsets_dict)\n",
    "\n",
    "# if angle_fname is not None:\n",
    "#     angles = pd.read_csv(angle_fname)\n",
    "#     bad_cols = ['fnum']\n",
    "#     ang_names = [col for col in angles.columns if col not in bad_cols]\n",
    "# else:\n",
    "ang_names = []\n",
    "angles = None\n",
    "\n",
    "ang_values = dict()\n",
    "\n",
    "for name in ang_names:\n",
    "    vals = np.array(angles[name])\n",
    "    angf = signal.medfilt(vals, kernel_size=5)\n",
    "    err = np.abs(angf - vals)\n",
    "    err[np.isnan(err)] = 10000\n",
    "\n",
    "    vals[err > 10] = np.nan\n",
    "    nans, ix = nan_helper(vals)\n",
    "    # some data missing, but not too much\n",
    "    if np.sum(nans) > 0 and np.sum(~nans) > 5:\n",
    "        vals[nans] = np.interp(ix(nans), ix(~nans), vals[~nans])\n",
    "\n",
    "    ang_values[name] = vals\n",
    "\n",
    "caps_2d = [cv2.VideoCapture(v) for v in fnames_2d]\n",
    "cap_3d = cv2.VideoCapture(fname_3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = get_plotting_params(caps_2d, cap_3d, ang_names)\n",
    "nframes = pp['nframes']\n",
    "fps = pp['fps']\n",
    "start_img = get_start_image(pp, ang_names)\n",
    "\n",
    "ang_window_size = 100\n",
    "pad_size = ang_window_size\n",
    "\n",
    "ang_values_padded = dict()\n",
    "for name, angles in ang_values.items():\n",
    "    ang_values_padded[name] = np.pad(angles, pad_size,\n",
    "                                        mode='constant', constant_values=np.nan)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "writer = cv2.VideoWriter(out_fname, fourcc, round(fps, ndigits=2),\n",
    "                            (pp['width_total'], pp['height_total']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_combined(config, pose_fname, cgroup, offsets_dict,\n",
    "                       fnames_2d, fname_3d, out_fname):\n",
    "\n",
    "    should_load_3d = (cgroup is not None) and \\\n",
    "        (pose_fname is not None) and \\\n",
    "        (offsets_dict is not None)\n",
    "\n",
    "    if should_load_3d:\n",
    "        scheme, bodyparts, points_2d_proj = get_projected_points(config, pose_fname, cgroup, offsets_dict)\n",
    "\n",
    "    # if angle_fname is not None:\n",
    "    #     angles = pd.read_csv(angle_fname)\n",
    "    #     bad_cols = ['fnum']\n",
    "    #     ang_names = [col for col in angles.columns if col not in bad_cols]\n",
    "    # else:\n",
    "    ang_names = []\n",
    "    angles = None\n",
    "\n",
    "    ang_values = dict()\n",
    "\n",
    "    for name in ang_names:\n",
    "        vals = np.array(angles[name])\n",
    "        angf = signal.medfilt(vals, kernel_size=5)\n",
    "        err = np.abs(angf - vals)\n",
    "        err[np.isnan(err)] = 10000\n",
    "\n",
    "        vals[err > 10] = np.nan\n",
    "        nans, ix = nan_helper(vals)\n",
    "        # some data missing, but not too much\n",
    "        if np.sum(nans) > 0 and np.sum(~nans) > 5:\n",
    "            vals[nans] = np.interp(ix(nans), ix(~nans), vals[~nans])\n",
    "\n",
    "        ang_values[name] = vals\n",
    "\n",
    "    caps_2d = [cv2.VideoCapture(v) for v in fnames_2d]\n",
    "    cap_3d = cv2.VideoCapture(fname_3d)\n",
    "\n",
    "    pp = get_plotting_params(caps_2d, cap_3d, ang_names)\n",
    "    nframes = pp['nframes']\n",
    "    fps = pp['fps']\n",
    "    start_img = get_start_image(pp, ang_names)\n",
    "\n",
    "    ang_window_size = 100\n",
    "    pad_size = ang_window_size\n",
    "\n",
    "    ang_values_padded = dict()\n",
    "    for name, angles in ang_values.items():\n",
    "        ang_values_padded[name] = np.pad(angles, pad_size,\n",
    "                                         mode='constant', constant_values=np.nan)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(out_fname, fourcc, round(fps, ndigits=2),\n",
    "                             (pp['width_total'], pp['height_total']))\n",
    "\n",
    "    q = queue.Queue(maxsize=50)\n",
    "\n",
    "    thread = threading.Thread(target=write_frame_thread,\n",
    "                              args=(writer, q))\n",
    "    thread.start()\n",
    "\n",
    "    for framenum in trange(nframes, ncols=70):\n",
    "        ret, frames_2d, frame_3d = read_frames(caps_2d, cap_3d)\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if should_load_3d:\n",
    "            frames_2d = draw_projected_points(\n",
    "                frames_2d, scheme, bodyparts, points_2d_proj[:, :, framenum])\n",
    "\n",
    "        all_angles = []\n",
    "        for angnum, name in enumerate(ang_names):\n",
    "            a = framenum + pad_size - ang_window_size//2\n",
    "            b = a + ang_window_size\n",
    "            angles = ang_values_padded[name][a:b]\n",
    "            all_angles.append(angles)\n",
    "\n",
    "        imout = draw_data(start_img, frames_2d, frame_3d, all_angles, pp)\n",
    "        q.put(imout)\n",
    "\n",
    "    for cap in caps_2d:\n",
    "        cap.release()\n",
    "    cap_3d.release()\n",
    "\n",
    "    q.put(None)\n",
    "    thread.join()\n",
    "    writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def write_frame_thread(writer, q):\n",
    "    while True:\n",
    "        frame = q.get(block=True)\n",
    "        if frame is None:\n",
    "            return\n",
    "        writer.write(frame)\n",
    "        # writer.writeFrame(frame)\n",
    "\n",
    "def turn_to_black(frame):\n",
    "    frame = np.float32(frame)\n",
    "    white = np.all(frame > 220, axis=2)\n",
    "    frame[white] = [0,0,0]\n",
    "    frame[~white] *= 1.5\n",
    "    frame = np.clip(frame, 0, 255).astype('uint8')\n",
    "    return frame\n",
    "\n",
    "\n",
    "def read_frames(caps_2d, cap_3d):\n",
    "    frames_2d = []\n",
    "    for cap in caps_2d:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            return False, None, None\n",
    "        # img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = frame\n",
    "        frames_2d.append(img)\n",
    "\n",
    "    ret, frame = cap_3d.read()\n",
    "    if not ret:\n",
    "        return False, None, None\n",
    "    frame_3d = frame\n",
    "    # frame_3d = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # frame_3d = turn_to_black(frame_3d)\n",
    "\n",
    "    return ret, frames_2d, frame_3d\n",
    "\n",
    "def get_video_params_cap(cap):\n",
    "    params = dict()\n",
    "    params['width'] = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    params['height'] = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    params['nframes'] = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    params['fps'] = cap.get(cv2.CAP_PROP_FPS)\n",
    "    return params\n",
    "\n",
    "def draw_seq(img, seq, rect, range_y=(None, None),\n",
    "             color=(0, 0, 0), thickness=5):\n",
    "    low, high = range_y\n",
    "\n",
    "    if low is None:\n",
    "        low = np.min(seq)\n",
    "    if high is None:\n",
    "        high = np.max(seq)\n",
    "    s = np.clip(seq, low, high)\n",
    "    s = (s - low)/(high-low)\n",
    "\n",
    "    left, right, top, bottom = rect\n",
    "    height = bottom - top\n",
    "\n",
    "    xs = np.linspace(left, right, num=len(seq))\n",
    "    ys = (1-s) * height + top\n",
    "    pointlist = list(zip(xs, ys))\n",
    "    pointlist = [(x, y) for x, y in pointlist if not np.isnan(y)]\n",
    "    pointlist = np.int32([pointlist])\n",
    "\n",
    "    cv2.polylines(img, pointlist, False, color,\n",
    "                  thickness=thickness, lineType=cv2.LINE_AA)\n",
    "\n",
    "def mapto(x, fromLow, fromHigh, toLow, toHigh):\n",
    "    norm = (x - fromLow) / (fromHigh-fromLow)\n",
    "    return norm * (toHigh - toLow) + toLow\n",
    "\n",
    "def draw_axis_y(img, rect, range_y, label,\n",
    "                num_ticks=5,\n",
    "                color=(0, 0, 0), thickness=5):\n",
    "    left, right, top, bottom = rect\n",
    "    height = bottom - top\n",
    "\n",
    "    left_start = left - 10\n",
    "\n",
    "    low, high = range_y\n",
    "    ticks = np.linspace(low, high, num_ticks+2)[1:-1]\n",
    "\n",
    "    cv2.line(img, (left_start, top+10), (left_start, bottom-10),\n",
    "             color, thickness=thickness)\n",
    "\n",
    "    font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = cv2.getFontScaleFromHeight(\n",
    "        font_face, int(round(height / (num_ticks + 3))))\n",
    "\n",
    "    for t in ticks:\n",
    "        y = mapto(t, low, high, bottom, top)\n",
    "        y = int(round(y))\n",
    "        lab = str(int(round(t)))\n",
    "        (w, h), baseline = cv2.getTextSize(lab, font_face, font_scale, 2)\n",
    "        cv2.line(img, (left_start-5, y), (left_start, y),\n",
    "                 color, thickness=thickness)\n",
    "        cv2.putText(img, lab, (left_start-30-w//2, y + baseline),\n",
    "                    font_face, 0.9, color, thickness=2)\n",
    "\n",
    "\n",
    "    imgnew = np.zeros((img.shape[1], img.shape[0]), dtype='uint8')\n",
    "    cv2.putText(imgnew, label, (img.shape[0] - top - 130, left-100), font_face, font_scale*0.7, 255, thickness=2)\n",
    "    imgnew = cv2.rotate(imgnew, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "    img[imgnew > 0] = color\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_plotting_params(caps_2d, cap_3d, ang_names=[]):\n",
    "\n",
    "    height_angle = 175\n",
    "    spacing_angle = 40\n",
    "    spacing_videos = 20\n",
    "\n",
    "    n_angles = len(ang_names)\n",
    "\n",
    "    params_2d = [get_video_params_cap(c) for c in caps_2d]\n",
    "    height_2d = max([p['height'] for p in params_2d])\n",
    "    widths_2d = [round(p['width'] * height_2d/p['height']) for p in params_2d]\n",
    "\n",
    "    param_3d = get_video_params_cap(cap_3d)\n",
    "    height_3d = param_3d['height']\n",
    "    width_3d = param_3d['width']\n",
    "\n",
    "    start_3d = height_2d + spacing_videos\n",
    "    start_angles = start_3d + height_3d + spacing_videos + spacing_angle\n",
    "\n",
    "    width_total = sum(widths_2d)\n",
    "    height_total = height_2d + spacing_videos + height_3d + spacing_videos + \\\n",
    "        height_angle * n_angles + spacing_angle*(n_angles+1)\n",
    "\n",
    "    nframes = min([p['nframes'] for p in params_2d])\n",
    "    nframes = min(nframes, param_3d['nframes'])\n",
    "\n",
    "    fps = param_3d['fps']\n",
    "\n",
    "    height_font = spacing_angle//2\n",
    "    font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = cv2.getFontScaleFromHeight(\n",
    "        font_face, height_font)\n",
    "    font_scale = int(round(font_scale))\n",
    "    font_color = (0, 0, 0)\n",
    "    font_thickness = 2\n",
    "\n",
    "    mid_3d = int((width_total - width_3d) / 2)\n",
    "\n",
    "    d = {\n",
    "        'height_angle': height_angle,\n",
    "        'spacing_angle': spacing_angle,\n",
    "        'spacing_videos': spacing_videos,\n",
    "\n",
    "        'height_2d': height_2d,\n",
    "        'widths_2d': widths_2d,\n",
    "        'start_3d': start_3d,\n",
    "        'width_3d': width_3d,\n",
    "        'mid_3d': mid_3d,\n",
    "        'height_3d': height_3d,\n",
    "\n",
    "        'nframes': nframes,\n",
    "        'fps': fps,\n",
    "\n",
    "        'width_total': width_total,\n",
    "        'height_total': height_total,\n",
    "\n",
    "        'start_3d': start_3d,\n",
    "        'start_angles': start_angles,\n",
    "\n",
    "        'height_font': height_font,\n",
    "        'font_face': font_face,\n",
    "        'font_scale': font_scale,\n",
    "        'font_color': font_color,\n",
    "        'font_thickness': font_thickness,\n",
    "    }\n",
    "\n",
    "    return d\n",
    "\n",
    "def get_start_image(pp, ang_names=[]):\n",
    "\n",
    "    start_img = np.zeros((pp['height_total'], pp['width_total'], 3), dtype='uint8')\n",
    "    start_img[:] = 255\n",
    "\n",
    "    for angnum, name in enumerate(ang_names):\n",
    "        start_y = pp['start_angles'] + (pp['height_angle'] + pp['spacing_angle'])*angnum\n",
    "        rect = (150, pp['width_total']-100, start_y, start_y + pp['height_angle'])\n",
    "\n",
    "        font_size, baseline = cv2.getTextSize(\n",
    "            name, pp['font_face'], pp['font_scale'], pp['font_thickness'])\n",
    "        fw, fh = font_size\n",
    "\n",
    "        text_xy = (pp['width_total'] // 2 - fw // 2, start_y)\n",
    "        cv2.putText(start_img, name, text_xy, pp['font_face'], pp['font_scale'], pp['font_color'],\n",
    "                    thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "        draw_axis_y(start_img, rect, (0, 180), 'Angle',\n",
    "                    num_ticks=3, thickness=4)\n",
    "\n",
    "    return start_img\n",
    "\n",
    "\n",
    "def draw_data(start_img, frames_2d, frame_3d, all_angles, pp):\n",
    "    height_2d = pp['height_2d']\n",
    "    widths_2d = pp['widths_2d']\n",
    "\n",
    "    start_3d = pp['start_3d']\n",
    "    height_3d = pp['height_3d']\n",
    "    width_3d = pp['width_3d']\n",
    "    mid_3d = pp['mid_3d']\n",
    "\n",
    "    start_angles = pp['start_angles']\n",
    "    height_angle = pp['height_angle']\n",
    "    spacing_angle = pp['spacing_angle']\n",
    "\n",
    "    width_total = pp['width_total']\n",
    "    height_total = pp['height_total']\n",
    "\n",
    "    frames_2d_resized = [cv2.resize(f, (w, height_2d))\n",
    "                         for f, w in zip(frames_2d, widths_2d)]\n",
    "\n",
    "    imout = np.copy(start_img)\n",
    "    imout[0:height_2d] = np.hstack(frames_2d_resized)\n",
    "    imout[start_3d:(start_3d + height_3d), mid_3d:(mid_3d+width_3d)] = frame_3d\n",
    "\n",
    "    data_color = (0,0,0)\n",
    "    indicator_color = (150,150,150)\n",
    "\n",
    "    for angnum, angles in enumerate(all_angles):\n",
    "        start_y = start_angles + (height_angle + spacing_angle)*angnum\n",
    "        rect = (150, width_total-100, start_y, start_y + height_angle)\n",
    "        left, right, top, bottom = rect\n",
    "\n",
    "        draw_seq(imout, angles, rect,\n",
    "                 range_y=(0, 180), color=data_color, thickness=2)\n",
    "        x = (left+right)//2\n",
    "        cv2.line(imout, (x, top+15), (x, bottom-15),\n",
    "                 indicator_color, thickness=2)\n",
    "\n",
    "    return imout\n",
    "\n",
    "## TODO: remove this function and import from project_2d.py\n",
    "def get_projected_points(config, pose_fname, cgroup, offsets_dict):\n",
    "    try:\n",
    "        scheme = config['labeling']['scheme']\n",
    "    except KeyError:\n",
    "        scheme = []\n",
    "\n",
    "    pose_data = pd.read_csv(pose_fname)\n",
    "    cols = [x for x in pose_data.columns if '_error' in x]\n",
    "    if len(scheme) == 0:\n",
    "        bodyparts = [c.replace('_error', '') for c in cols]\n",
    "    else:\n",
    "        bodyparts = sorted(set([x for dx in scheme for x in dx]))\n",
    "\n",
    "    M = np.identity(3)\n",
    "    center = np.zeros(3)\n",
    "    for i in range(3):\n",
    "        center[i] = np.mean(pose_data['center_{}'.format(i)])\n",
    "        for j in range(3):\n",
    "            M[i, j] = np.mean(pose_data['M_{}{}'.format(i, j)])\n",
    "\n",
    "    bp_dict = dict(zip(bodyparts, range(len(bodyparts))))\n",
    "\n",
    "    all_points = np.array([np.array(pose_data.loc[:, (bp+'_x', bp+'_y', bp+'_z')])\n",
    "                           for bp in bodyparts])\n",
    "\n",
    "    all_errors = np.array([np.array(pose_data.loc[:, bp+'_error'])\n",
    "                           for bp in bodyparts])\n",
    "\n",
    "    if config['triangulation']['optim']:\n",
    "        all_errors[np.isnan(all_errors)] = 0\n",
    "    else:\n",
    "        all_errors[np.isnan(all_errors)] = 10000\n",
    "    good = (all_errors < 100)\n",
    "    all_points[~good] = np.nan\n",
    "\n",
    "    n_joints, n_frames, _ = all_points.shape\n",
    "    n_cams = len(cgroup.cameras)\n",
    "\n",
    "    all_points_flat = all_points.reshape(-1, 3)\n",
    "    all_points_flat_t = (all_points_flat + center).dot(np.linalg.inv(M.T))\n",
    "\n",
    "    points_2d_proj_flat = cgroup.project(all_points_flat_t)\n",
    "    points_2d_proj = points_2d_proj_flat.reshape(n_cams, n_joints, n_frames, 2)\n",
    "\n",
    "    cam_names = cgroup.get_names()\n",
    "    for cix, cname in enumerate(cam_names):\n",
    "        offset = offsets_dict[cname]\n",
    "        dx, dy = offset[0], offset[1]\n",
    "        points_2d_proj[cix, :, :, 0] -= dx\n",
    "        points_2d_proj[cix, :, :, 1] -= dy\n",
    "\n",
    "    return scheme, bodyparts, points_2d_proj\n",
    "\n",
    "\n",
    "def draw_projected_points(frames_2d, scheme, bodyparts, points):\n",
    "    n_cams, n_joints, _ = points.shape\n",
    "    out = []\n",
    "    for cix, frame in enumerate(frames_2d):\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_out = label_frame(img, points[cix], scheme, bodyparts)\n",
    "        img_out = cv2.cvtColor(frame_out, cv2.COLOR_RGB2BGR)\n",
    "        out.append(img_out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_2d = [c(c) for c in caps_2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anipose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
