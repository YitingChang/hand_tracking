{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference and triangulation pipeline\n",
    "# \n",
    "# Input: \n",
    "#       Raw videos from different camera views\n",
    "# Output:\n",
    "#       LP output: 2D pose estimation \n",
    "#       Anipose output: 3D pose estimation and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import toml\n",
    "\n",
    "from utils.lp2anipose import lp2anipose_session\n",
    "from utils.visualization import creat_combined_video\n",
    "from anipose_yt.compute_angles import process_trial as angles_process\n",
    "from anipose_yt.triangulate import process_trial as triangulate_process\n",
    "from anipose_yt.filter_pose import process_trial as filter2d_process\n",
    "from anipose_yt.label_combined import process_trial as v2d3d_process\n",
    "from anipose_yt.label_videos_3d import process_trial as v3d_process\n",
    "from anipose_yt.filter_3d import process_trial as filter3d_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting\n",
    "data_dir = r\"/home/yiting/Documents/Data\"\n",
    "analysis_dir = r\"/home/yiting/Documents/Analysis\"\n",
    "session_name = \"2024-11-22\"\n",
    "camera_views = [\"To\", \"TL\", \"TR\", \"BL\", \"BR\"]\n",
    "\n",
    "lp_dir = os.path.join(analysis_dir, session_name, \"litpose\")\n",
    "ap_dir = os.path.join(analysis_dir, session_name, \"anipose\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning Pose\n",
    "### Rename and reorganize videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(lp_dir, \"new_videos\"), exist_ok = True)\n",
    "trials = sorted(os.listdir(os.path.join(data_dir, session_name, \"cameras\")))\n",
    "for t in trials[50:60]:\n",
    "    trialname_parts = t.split('_')\n",
    "    for c in camera_views:\n",
    "        raw_vid_file = os.path.join(data_dir, session_name, \"cameras\", t, \"cam\" + c +\".mp4\")\n",
    "        new_vid_name = trialname_parts[0] + \"_\" + trialname_parts[1] + \"_\" + \"cam\" + c + \".mp4\"\n",
    "        lp_vid_file = os.path.join(lp_dir, \"new_videos\", new_vid_name)\n",
    "        shutil.copyfile(raw_vid_file, lp_vid_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference @ Rockfish Cluster\n",
    "\n",
    "Run inference on new videos  \n",
    "\n",
    "1. Upload new videos to Rockfish cluster (projects/hand_tracking/lightning-pose-gpu/data/new_videos/session_name)\n",
    "\n",
    "2. Edit litpose configuration file\\\n",
    "    eval.hydra_paths: path to models to use for prediction\\\n",
    "    eval.test_videos_directory: path to a directory containing videos to run inference on\\\n",
    "    eval.save_vids_after_training: if true, the script will also save a copy of the full video with model predictions overlaid.\n",
    "\n",
    "3. Edit sbatch script (projects/hand_tracking/lightning-pose-gpu/inference_4gpu.sh)\\\n",
    "###Run the python script\\\n",
    "srun python scripts/predict_new_vids.py --config-path=/vast/doconn15/projects/hand_tracking/lightning-pose-gpu/data --config-name=config_inference.yaml\n",
    "\n",
    "4. Submit job script on Rockfish cluster\\\n",
    "Terminal:\\\n",
    "cd vast-doconn15/projects/hand_tracking/lightning-pose-gpu\\\n",
    "sbatch inference_1gpu.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anipose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = os.path.join(analysis_dir, \"anipose_config.toml\")\n",
    "calib_folder = os.path.join(analysis_dir, \"anipose_calibration\")\n",
    "# Load config file\n",
    "config = toml.load(config_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert and reorganize LP outputs\n",
    "1. Download Lightning Pose outputs from Rockfish cluster (outputs/YYYY-MM-DD/HH-MM-SS/video_preds)\n",
    "2. Convert Lightning pose 2d outputs (.csv) to Anipose inputs (.hdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_2d_dir = os.path.join(lp_dir, \"video_preds\")\n",
    "ap_2d_dir = os.path.join(ap_dir, \"pose_2d\")\n",
    "os.makedirs(ap_2d_dir, exist_ok = True)\n",
    "lp2anipose_session(lp_2d_dir, ap_2d_dir, camera_views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering 2D data\n",
    "The filter applied over the 2D data functions as a threshold filter. Predicted labels that do not fall within the threshold are removed and replaced with a new prediction that is determined by interpolating. In config.toml, the parameter spline can be set to true for interpolation using a cubic spline, or false for linear interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_2d_dir = os.path.join(ap_dir, \"pose_2d\")\n",
    "trials = sorted(os.listdir(ap_2d_dir))\n",
    "for t in trials:\n",
    "    filter2d_process(config, session_name, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_2d_dir = os.path.join(ap_dir, \"pose_2d\")\n",
    "trials = sorted(os.listdir(ap_2d_dir))\n",
    "for t in trials:\n",
    "    triangulate_process(config, session_name, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering 3D data\n",
    "The filter applied over the 3D data functions as a threshold filter. Predicted labels that do not fall within the threshold are removed and replaced with a new prediction that is determined by interpolating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['filter']['enabled']:\n",
    "    ap_2d_dir = os.path.join(ap_dir, \"pose_2d_filter\")\n",
    "trials = sorted(os.listdir(ap_2d_dir))\n",
    "for t in trials:\n",
    "    filter3d_process(config, session_name, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "Compute hand configuration parameters (length, angle, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['filter']['enabled']:\n",
    "    ap_2d_dir = os.path.join(ap_dir, \"pose_2d_filter\")\n",
    "trials = sorted(os.listdir(ap_2d_dir))\n",
    "for t in trials:\n",
    "    angles_process(config, session_name, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labeled 3d videos\n",
    "ap_2d_dir = os.path.join(ap_dir, \"pose_2d\")\n",
    "trials = os.listdir(ap_2d_dir)\n",
    "for t in trials:\n",
    "    v3d_process(config, session_name, t, filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined videos that have reprojected labeled 2d videos, labeled 3d videos, and angle traces across time. \n",
    "ap_2d_dir = os.path.join(ap_dir, \"pose_2d\")\n",
    "trials = os.listdir(ap_2d_dir)\n",
    "for t in trials:\n",
    "    v2d3d_process(config, session_name, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined videos that have a 2d video from a single camera view and selected angles\n",
    "ap_2d_dir = os.path.join(ap_dir, \"pose_2d\")\n",
    "trials = sorted(os.listdir(ap_2d_dir))\n",
    "camera_view = 'camTL'\n",
    "feature_columns = ['index_mcp', 'middle_mcp', 'ring_mcp', 'ring_mcp']\n",
    "# feature_columns = ['index_dip', 'index_pip', 'index_mcp']\n",
    "# feature_columns = ['index_pip', 'middle_pip', 'ring_pip', 'ring_pip']\n",
    "# feature_columns = ['index_dip', 'middle_dip', 'ring_dip', 'ring_dip']\n",
    "# feature_columns = ['middle_dip', 'middle_pip', 'middle_mcp']\n",
    "# feature_columns = ['thumb_ip', 'thumb_mcp']\n",
    "\n",
    "if len(trials) > 0:\n",
    "    os.makedirs(os.path.join(analysis_dir, session_name, 'anipose', 'videos_v2d_angles'), exist_ok=True)\n",
    "for t in trials:\n",
    "    video_path = os.path.join(data_dir, session_name, 'cameras', t, t + '_' + camera_view + '.mp4')\n",
    "    traces_csv = os.path.join(analysis_dir, session_name, 'anipose', 'angles', t + '_angles.csv')\n",
    "    output_path = os.path.join(analysis_dir, session_name, 'anipose', 'videos_v2d_angles', t + '_' + camera_view + '_mcp.mp4')\n",
    "    if os.path.exists(output_path):\n",
    "        continue\n",
    "    creat_combined_video(video_path, traces_csv, output_path, feature_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anipose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
